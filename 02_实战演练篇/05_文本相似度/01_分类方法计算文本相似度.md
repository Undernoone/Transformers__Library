# 分类方法计算文本相似度

#### **1. 导入依赖**

```python
import torch
import evaluate
from datasets import load_dataset
from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, \
    DataCollatorWithPadding, pipeline
```

- **`torch`**: PyTorch 库，用于深度学习模型的训练和推理。
- **`evaluate`**: Hugging Face 的评估库，用于加载和计算模型评估指标（如准确率、F1 分数）。
- **`load_dataset`**: 从 Hugging Face 的 `datasets` 库加载数据集。
- **`AutoTokenizer`**: 自动加载预训练模型的分词器。
- **`AutoModelForSequenceClassification`**: 自动加载用于序列分类任务的预训练模型。
- **`Trainer`**: Hugging Face 提供的训练器，简化训练和评估流程。
- **`TrainingArguments`**: 定义训练的超参数。
- **`DataCollatorWithPadding`**: 数据整理器，用于将输入数据填充到相同长度。
- **`pipeline`**: Hugging Face 提供的推理管道，简化模型推理过程。

------

#### **2. 加载数据集**

```python
datasets = load_dataset("json", data_files="./train_pair_1w.json", split="train")
datasets = datasets.train_test_split(test_size=0.2)
```

- **`load_dataset`**: 从 JSON 文件加载数据集，文件路径为 `./train_pair_1w.json`。
- **`train_test_split`**: 将数据集划分为训练集和测试集，测试集占 20%。

------

#### **3. 加载分词器**

```python
tokenizer = AutoTokenizer.from_pretrained("hfl/chinese-macbert-base")
print(datasets["train"][0]) # 可以看到包括sentence1, sentence2, label三个字符串字段
```

- **`AutoTokenizer.from_pretrained`**: 加载预训练的中文 MacBERT 模型的分词器。
- **`print(datasets["train"][0])`**: 打印训练集的第一个样本，查看数据结构。样本包含 `sentence1`、`sentence2` 和 `label` 三个字段。

------

#### **4. 数据预处理**

```python
def preprocess_function(examples):
    tokenized_examples = tokenizer(examples["sentence1"], examples["sentence2"], truncation=True, max_length=128)
    tokenized_examples["label"] = [float(label) for label in examples["label"]]
    return tokenized_examples
```

- **`tokenizer`**: 对 `sentence1` 和 `sentence2` 进行分词，并截断到最大长度 128。
- **`tokenized_examples["label"]`**: 将标签从字符串转换为浮点数，因为神经网络训练需要数值型标签。

------

#### **5. 应用预处理**

```python
tokenized_datasets = datasets.map(preprocess_function, batched=True, remove_columns=datasets["train"].column_names)
```

- **`datasets.map`**: 对数据集应用 `preprocess_function`，以批处理方式执行。
- **`remove_columns`**: 移除原始列，只保留分词后的数据和标签。

------

#### **6. 加载预训练模型**

```python
model = AutoModelForSequenceClassification.from_pretrained("hfl/chinese-macbert-base")
```

- **`AutoModelForSequenceClassification.from_pretrained`**: 加载预训练的中文 MacBERT 模型，用于序列分类任务。

------

#### **7. 加载评估指标**

```python
acc_metric = evaluate.load("accuracy")
f1_metric = evaluate.load("f1")
```

- **`evaluate.load`**: 加载准确率和 F1 分数评估指标。

------

#### **8. 定义评估函数**

```python
def eval_metric(eval_predict):
    predictions, labels = eval_predict
    predictions = torch.tensor(predictions)
    predictions = torch.argmax(predictions, axis=-1)
    acc = acc_metric.compute(predictions=predictions, references=labels)
    f1 = f1_metric.compute(predictions=predictions, references=labels)
    acc.update(f1)
    return acc
```

- **`predictions`**: 模型输出的预测结果。
- **`torch.argmax`**: 获取预测结果中概率最大的类别。
- **`acc_metric.compute`**: 计算准确率。
- **`f1_metric.compute`**: 计算 F1 分数。
- **`acc.update(f1)`**: 将 F1 分数合并到准确率字典中。

------

#### **9. 定义训练参数**

```python
training_args = TrainingArguments(
    output_dir='./文本相似度',
    per_device_train_batch_size=32,
    per_device_eval_batch_size=32,
    num_train_epochs=1,
    logging_steps=10,
    evaluation_strategy="epoch",
    save_strategy="epoch",
    save_total_limit=3,
    learning_rate=2e-5,
    weight_decay=0.01,
    metric_for_best_model="f1",
    load_best_model_at_end=True,
)
```

- **`output_dir`**: 模型和日志保存的目录。
- **`per_device_train_batch_size`**: 每个设备的训练批次大小。
- **`num_train_epochs`**: 训练的总轮数。
- **`logging_steps`**: 每隔多少步记录一次日志。
- **`evaluation_strategy`**: 每个 epoch 结束后进行评估。
- **`save_strategy`**: 每个 epoch 结束后保存模型。
- **`save_total_limit`**: 最多保存 3 个模型。
- **`learning_rate`**: 学习率。
- **`weight_decay`**: 权重衰减（L2 正则化）。
- **`metric_for_best_model`**: 以 F1 分数作为选择最佳模型的指标。
- **`load_best_model_at_end`**: 训练结束后加载最佳模型。

------

#### **10. 定义训练器**

```python
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["test"],
    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),
    compute_metrics=eval_metric)
```

- **`Trainer`**: 初始化训练器，传入模型、训练参数、数据集、数据整理器和评估函数。

------

#### **11. 训练和评估**

```python
trainer.train()
trainer.evaluate(tokenized_datasets["test"])
```

- **`trainer.train`**: 开始训练模型。
- **`trainer.evaluate`**: 在测试集上评估模型性能。

------

#### **12. 设置标签映射**

```python
model.config.id2label = {0:"不相似",1:"相似"}
```

- **`id2label`**: 将模型输出的类别 ID 映射为人类可读的标签。

------

#### **13. 定义推理管道**

```python
pipe = pipeline("text-classification", model=model, tokenizer=tokenizer, device=0)
```

- **`pipeline`**: 初始化文本分类推理管道，使用 GPU（`device=0`）进行推理。

------

#### **14. 推理示例**

```python
print(pipe({"text":"你是谁","text_pair":"我是谁"}))
```

- **`pipe`**: 对输入的句子对进行推理，输出分类结果（相似或不相似）。

------

