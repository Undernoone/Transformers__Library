# 多项选择

#### **导入模块**

```python
from typing import Any
import torch
import evaluate
import numpy as np
from datasets import load_dataset
from transformers import AutoTokenizer, AutoModelForMultipleChoice, Trainer, TrainingArguments
```

- 功能：导入必要的库和模块。
  - `torch`：PyTorch 深度学习框架。
  - `evaluate`：用于评估模型性能的库。
  - `numpy`：数值计算库。
  - `datasets`：用于加载和处理数据集的库。
  - `transformers`：Hugging Face 提供的预训练模型和工具。

------

#### **2. 加载数据集**

```python
dataset = load_dataset("clue/clue", "c3")
dataset.pop("test")
```

- 功能：加载 CLUE 数据集中的 C3 子集，并移除测试集。
  - `load_dataset`：从 Hugging Face 数据集库中加载指定数据集。
  - `pop("test")`：移除测试集，仅保留训练集和验证集。

------

#### **3. 数据子集化**

```python
dataset["train"] = dataset["train"].select(range(100))
dataset["validation"] = dataset["validation"].select(range(50))
```

- 功能：为了快速演示，仅使用训练集的前 100 条数据和验证集的前 50 条数据。
  - `select(range(n))`：从数据集中选择前 `n` 条数据。

------

#### **4. 加载分词器**

```python
tokenizer = AutoTokenizer.from_pretrained("hfl/chinese-macbert-base")
```

- 功能：加载预训练的分词器。
  - `AutoTokenizer.from_pretrained`：从 Hugging Face 模型库中加载指定模型的分词器。

------

#### **5. 数据预处理函数**

```python
def preprocess_function(examples):
    context = []
    questions_choices = []
    labels = []
    for index in range(len(examples["context"])):
        ctx = "\n".join(examples["context"][index])
        question = examples["question"][index]
        choices = examples["choice"][index]
        for choice in choices:
            context.append(ctx)
            questions_choices.append(question + " " + choice)
        if len(choices) < 4:
            for _ in range(4-len(choices)):
                context.append(ctx)
                questions_choices.append(question + " " + "不知道")
        labels.append(choices.index(examples["answer"][index]))
    tokenized_examples = tokenizer(context, questions_choices, padding="max_length", max_length=256, truncation="only_first")
    tokenized_examples = {k: [v[i:i+4] for i in range(0, len(v), 4)] for k, v in tokenized_examples.items()}
    tokenized_examples["labels"] = labels
    return tokenized_examples
```

- 功能：将原始数据转换为模型可接受的输入格式。
  - 解析 `context`、`question` 和 `choices`，并将它们组合成模型输入。
  - 如果选项少于 4 个，用“不知道”填充。
  - 使用分词器对输入进行编码，并生成标签（正确答案的索引）。

------

#### **6. 应用预处理**

```python
tokenized_datasets = dataset.map(preprocess_function, batched=True)
print(tokenized_datasets)
```

- 功能：对整个数据集应用预处理函数。
  - `map`：将预处理函数应用于数据集的每个批次。
  - `batched=True`：以批次方式处理数据，提高效率。

------

#### **7. 加载模型**

```python
model = AutoModelForMultipleChoice.from_pretrained("hfl/chinese-macbert-base")
```

- 功能：加载预训练的多选模型。
  - `AutoModelForMultipleChoice.from_pretrained`：加载 Hugging Face 提供的多选任务模型。

------

#### **8. 加载评估指标**

```python
accuracy = evaluate.load("accuracy")
```

- 功能：加载准确率评估指标。
  - `evaluate.load`：加载指定的评估指标。

------

#### **9. 定义计算指标的函数**

```python
def compute_metrics(pred):
    predictions, labels = pred
    predictions = np.argmax(predictions, axis=-1)
    return accuracy.compute(predictions=predictions, references=labels)
```

- 功能：计算模型的准确率。
  - `np.argmax`：获取预测结果中概率最大的类别。
  - `accuracy.compute`：计算预测结果与真实标签的准确率。

------

#### **10. 定义训练参数**

```python
training_args = TrainingArguments(
    output_dir="./muliple_choice",
    per_device_train_batch_size=16,
    per_device_eval_batch_size=16,
    num_train_epochs=3,
    logging_steps=50,
    eval_strategy="epoch",
    save_strategy="epoch",
    load_best_model_at_end=True,
    fp16=True,
)
```

- 功能：配置训练参数。
  - `output_dir`：模型和日志的输出目录。
  - `per_device_train_batch_size`：每个设备的训练批次大小。
  - `num_train_epochs`：训练轮数。
  - `fp16`：启用混合精度训练，加速训练过程。

------

#### **11. 初始化 Trainer**

```python
trainer = Trainer(
    model=model,
    args=training_args,
    tokenizer=tokenizer,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation"],
    compute_metrics=compute_metrics
)
```

- 功能：初始化 Trainer 对象，用于训练和评估模型。
  - `model`：要训练的模型。
  - `args`：训练参数。
  - `tokenizer`：分词器。
  - `train_dataset`：训练数据集。
  - `eval_dataset`：验证数据集。
  - `compute_metrics`：评估指标计算函数。

------

#### **12. 训练模型**

```python
trainer.train()
```

- **功能**：开始训练模型。

------

#### **13. 自定义多选任务 Pipeline**

```python
class MultipleChoicePipeline:
    def __init__(self, model, tokenizer) -> None:
        self.model = model
        self.tokenizer = tokenizer
        self.device = model.device

    def preprocess(self, context, quesiton, choices):
        cs, qcs = [], []
        for choice in choices:
            cs.append(context)
            qcs.append(quesiton + " " + choice)
        return tokenizer(cs, qcs, truncation="only_first", max_length=256, return_tensors="pt")

    def predict(self, inputs):
        inputs = {k: v.unsqueeze(0).to(self.device) for k, v in inputs.items()}
        return self.model(**inputs).logits

    def postprocess(self, logits, choices):
        predition = torch.argmax(logits, dim=-1).cpu().item()
        return choices[predition]

    def __call__(self, context, question, choices) -> Any:
        inputs = self.preprocess(context, question, choices)
        logits = self.predict(inputs)
        result = self.postprocess(logits, choices)
        return result
```

- 功能：自定义一个多选任务的处理流程。
  - `preprocess`：对输入进行预处理。
  - `predict`：使用模型进行推理。
  - `postprocess`：将模型输出转换为最终结果。

------

#### **14. 使用 Pipeline 进行推理**

```python
pipe = MultipleChoicePipeline(model, tokenizer)
print(pipe("小明在北京上班", "小明在哪里上班？", ["北京", "上海", "河北", "海南", "河北", "海南"]))
```

- **功能**：使用自定义 Pipeline 对输入进行推理，并输出结果。

